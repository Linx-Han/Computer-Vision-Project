# model.py
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from tqdm import tqdm
import os
import matplotlib.pyplot as plt
from data import get_dataloaders

# ============= è½»é‡ç‰ˆæ¨¡å‹å®šä¹‰ =============
class CalorieEstimatorCNN(nn.Module):
    """åŒæµCNNï¼šåˆ†åˆ«å¤„ç†RGBå’ŒDepthï¼Œç„¶åèåˆ"""
    def __init__(self):
        super(CalorieEstimatorCNN, self).__init__()
        
        # RGBæµ - åªç”¨3å±‚å·ç§¯
        self.rgb_stream = nn.Sequential(
            # Conv1
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 224 -> 112
            
            # Conv2
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 112 -> 56
            
            # Conv3
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1))  # å…¨å±€å¹³å‡æ± åŒ–
        )
        
        # Depthæµ - åªç”¨3å±‚å·ç§¯
        self.depth_stream = nn.Sequential(
            # Conv1
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            # Conv2
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),
            
            # Conv3
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        # èåˆå±‚ + å›å½’å¤´ - æ›´ç®€å•
        self.fusion = nn.Sequential(
            nn.Linear(256, 128),  # 128 + 128 = 256
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 1)
        )
    
    def forward(self, rgb, depth):
        # æå–ç‰¹å¾
        rgb_feat = self.rgb_stream(rgb).flatten(1)      # [batch, 128]
        depth_feat = self.depth_stream(depth).flatten(1) # [batch, 128]
        
        # èåˆ
        fused = torch.cat([rgb_feat, depth_feat], dim=1) # [batch, 256]
        
        # å›å½’
        calories = self.fusion(fused).squeeze(1)         # [batch]
        
        return calories


# ============= è®­ç»ƒå‡½æ•° =============
def train_epoch(model, train_loader, criterion, optimizer, device):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0
    
    for rgb, depth, calories in tqdm(train_loader, desc='Training'):
        rgb = rgb.to(device)
        depth = depth.to(device)
        calories = calories.to(device)
        
        # å‰å‘ä¼ æ’­
        pred_calories = model(rgb, depth)
        loss = criterion(pred_calories, calories)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    avg_loss = total_loss / len(train_loader)
    return avg_loss


def validate(model, val_loader, criterion, device):
    """éªŒè¯"""
    model.eval()
    total_loss = 0
    
    with torch.no_grad():
        for rgb, depth, calories in tqdm(val_loader, desc='Validation'):
            rgb = rgb.to(device)
            depth = depth.to(device)
            calories = calories.to(device)
            
            pred_calories = model(rgb, depth)
            loss = criterion(pred_calories, calories)
            
            total_loss += loss.item()
    
    avg_loss = total_loss / len(val_loader)
    return avg_loss


def plot_training_history(history, save_path='training_results.png'):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    epochs = range(1, len(history['train_loss']) + 1)
    
    # 1. Lossæ›²çº¿
    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)
    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)
    axes[0, 0].set_xlabel('Epoch', fontsize=12)
    axes[0, 0].set_ylabel('Loss (MSE)', fontsize=12)
    axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')
    axes[0, 0].legend(fontsize=11)
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. RMSEæ›²çº¿
    axes[0, 1].plot(epochs, history['val_rmse'], 'g-', linewidth=2)
    axes[0, 1].set_xlabel('Epoch', fontsize=12)
    axes[0, 1].set_ylabel('RMSE', fontsize=12)
    axes[0, 1].set_title('Validation RMSE', fontsize=14, fontweight='bold')
    axes[0, 1].grid(True, alpha=0.3)
    
    # æ‰¾åˆ°æœ€ä½³epoch
    best_epoch = np.argmin(history['val_loss']) + 1
    best_rmse = history['val_rmse'][best_epoch - 1]
    axes[0, 1].axvline(x=best_epoch, color='r', linestyle='--', linewidth=2, 
                       label=f'Best: Epoch {best_epoch}, RMSE={best_rmse:.2f}')
    axes[0, 1].legend(fontsize=10)
    
    # 3. Train vs Val Losså¯¹æ¯”
    axes[1, 0].plot(epochs, history['train_loss'], 'b-', label='Train', linewidth=2)
    axes[1, 0].plot(epochs, history['val_loss'], 'r-', label='Validation', linewidth=2)
    axes[1, 0].fill_between(epochs, history['train_loss'], history['val_loss'], 
                            alpha=0.3, color='gray', label='Gap')
    axes[1, 0].set_xlabel('Epoch', fontsize=12)
    axes[1, 0].set_ylabel('Loss', fontsize=12)
    axes[1, 0].set_title('Overfitting Check (Train-Val Gap)', fontsize=14, fontweight='bold')
    axes[1, 0].legend(fontsize=11)
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. ç»Ÿè®¡æ‘˜è¦
    axes[1, 1].axis('off')
    summary_text = f"""
    Training Summary
    ================
    
    Total Epochs: {len(epochs)}
    
    Best Performance:
    â€¢ Epoch: {best_epoch}
    â€¢ Val Loss: {history['val_loss'][best_epoch-1]:.4f}
    â€¢ Val RMSE: {best_rmse:.4f}
    
    Final Performance:
    â€¢ Train Loss: {history['train_loss'][-1]:.4f}
    â€¢ Val Loss: {history['val_loss'][-1]:.4f}
    â€¢ Val RMSE: {history['val_rmse'][-1]:.4f}
    
    Improvement:
    â€¢ Initial RMSE: {history['val_rmse'][0]:.4f}
    â€¢ Best RMSE: {best_rmse:.4f}
    â€¢ Reduction: {history['val_rmse'][0] - best_rmse:.4f}
    """
    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, family='monospace',
                    verticalalignment='center')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nâœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")
    plt.close()


# ============= ä¸»è®­ç»ƒæµç¨‹ =============
def main():
    # è¶…å‚æ•° - é’ˆå¯¹å°æ•°æ®é›†ä¼˜åŒ–
    BATCH_SIZE = 32
    EPOCHS = 50
    LEARNING_RATE = 0.001  
    VAL_SPLIT = 0.2
    
    # è·¯å¾„
    ROOT_DIR = os.getenv('DATA_ROOT_DIR', './data')
    CSV_FILE = os.getenv('TRAIN_CSV_FILE', './data/nutrition5k_train.csv')
    CHECKPOINT_DIR = os.getenv('CHECKPOINT_DIR', './checkpoints')
    print(f"ğŸ“ æ•°æ®æ ¹ç›®å½•: {ROOT_DIR}")
    print(f"ğŸ“„ è®­ç»ƒCSVæ–‡ä»¶: {CSV_FILE}")
    print(f"ğŸ’¾ æ£€æŸ¥ç‚¹ç›®å½•: {CHECKPOINT_DIR}")
    
    # è®¾å¤‡
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("âœ… ä½¿ç”¨ Apple Silicon GPU (MPS)")
    else:
        device = torch.device("cpu")
        print("âš ï¸ ä½¿ç”¨ CPU")
    
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs('checkpoints', exist_ok=True)
    
    # æ•°æ®åŠ è½½
    print("\nåŠ è½½æ•°æ®...")
    train_loader, val_loader = get_dataloaders(
        root_dir=ROOT_DIR,
        csv_file=CSV_FILE,
        batch_size=BATCH_SIZE,
        val_split=VAL_SPLIT
    )
    print(f"è®­ç»ƒé›†: {len(train_loader.dataset)} æ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_loader.dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = CalorieEstimatorCNN().to(device)
    
    # æ‰“å°æ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,} (å¯è®­ç»ƒ: {trainable_params:,})")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6
    )
    
    # è®°å½•è®­ç»ƒå†å²
    history = {
        'train_loss': [],
        'val_loss': [],
        'val_rmse': []
    }
    
    # è®­ç»ƒ
    print("\nå¼€å§‹è®­ç»ƒ...\n")
    best_val_loss = float('inf')
    patience_counter = 0
    early_stop_patience = 20
    
    for epoch in range(EPOCHS):
        print(f"Epoch {epoch+1}/{EPOCHS}")
        print("-" * 50)
        
        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)
        
        # éªŒè¯
        val_loss = validate(model, val_loader, criterion, device)
        val_rmse = np.sqrt(val_loss)
        
        # è®°å½•å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']
        
        # è°ƒæ•´å­¦ä¹ ç‡
        old_lr = current_lr
        scheduler.step(val_loss)
        new_lr = optimizer.param_groups[0]['lr']
        
        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_rmse'].append(val_rmse)
        
        print(f"Train Loss: {train_loss:.4f}")
        print(f"Val Loss: {val_loss:.4f}")
        print(f"Val RMSE: {val_rmse:.4f}")
        print(f"Learning Rate: {new_lr:.6f}")
        
        # å¦‚æœå­¦ä¹ ç‡æ”¹å˜äº†ï¼Œæ‰“å°æç¤º
        if new_lr < old_lr:
            print(f"âš  å­¦ä¹ ç‡é™ä½: {old_lr:.6f} -> {new_lr:.6f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
                'val_rmse': val_rmse,
            }, 'checkpoints/best_model.pth')
            print(f"âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (Val Loss: {val_loss:.4f}, RMSE: {val_rmse:.4f})")
        else:
            patience_counter += 1
            if patience_counter >= early_stop_patience:
                print(f"\nâš  æ—©åœè§¦å‘ï¼{early_stop_patience} ä¸ªepochæ²¡æœ‰æ”¹å–„")
                break
        
        print()
    
    # ä¿å­˜è®­ç»ƒå†å²
    np.save('checkpoints/training_history.npy', history)
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    print("\nç”Ÿæˆè®­ç»ƒå¯è§†åŒ–...")
    plot_training_history(history, save_path='checkpoints/training_results.png')
    
    print("\nè®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³éªŒè¯Loss: {best_val_loss:.4f}")
    print(f"æœ€ä½³éªŒè¯RMSE: {np.sqrt(best_val_loss):.4f}")
    
    # æ‰“å°æœ€åå‡ ä¸ªepochçš„ç»“æœ
    print("\næœ€å5ä¸ªepoch:")
    for i in range(max(0, len(history['val_rmse'])-5), len(history['val_rmse'])):
        print(f"  Epoch {i+1}: Train Loss={history['train_loss'][i]:.4f}, "
              f"Val Loss={history['val_loss'][i]:.4f}, "
              f"Val RMSE={history['val_rmse'][i]:.4f}")


if __name__ == '__main__':
    main()